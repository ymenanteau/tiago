{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from open3d import *\n",
    "import copy\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_path = 'scene_6.ply'\n",
    "model_path = 'data/Model3D/Model_pringles.ply'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load a ply point cloud, print it, and render it\n"
     ]
    }
   ],
   "source": [
    "print(\"Load a ply point cloud, print it, and render it\")\n",
    "pcd = read_point_cloud(scene_path)\n",
    "# Flip it, otherwise the pointcloud will be upside down\n",
    "pcd.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])\n",
    "draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load a ply point cloud, print it, and render it\n"
     ]
    }
   ],
   "source": [
    "print(\"Load a ply point cloud, print it, and render it\")\n",
    "pcd = read_point_cloud(model_path)\n",
    "pcd.paint_uniform_color([1, 0.706, 0])\n",
    "# Flip it, otherwise the pointcloud will be upside down\n",
    "pcd.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])\n",
    "draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_registration_result(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    #source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    #target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "    draw_geometries([source_temp, target_temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial alignment\n",
      "RegistrationResult with fitness = 1.000000, inlier_rmse = 0.267580, and correspondence_set size of 11017\n",
      "Access transformation to get result.\n",
      "Apply point-to-point ICP\n",
      "RegistrationResult with fitness = 1.000000, inlier_rmse = 0.034289, and correspondence_set size of 11017\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.36816138  0.72358105 -0.69449533  0.08401925]\n",
      " [-0.45977583  0.73259596  0.6753407  -0.79065387]\n",
      " [ 0.95370508  0.06985421  0.60404071  0.80911247]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "source = read_point_cloud(model_path)\n",
    "target = read_point_cloud(scene_path)\n",
    "threshold = 1\n",
    "trans_init = np.asarray(\n",
    "            [[1, 0.011, -0.507,  0],\n",
    "            [-0.139, 1, -0.215,  -1],\n",
    "            [0.487, 0.255,  1, 0.8],\n",
    "            [0.0, 0.0, 0.0, 1.0]])\n",
    "draw_registration_result(source, target, trans_init)\n",
    "print(\"Initial alignment\")\n",
    "evaluation = evaluate_registration(source, target,\n",
    "        threshold, trans_init)\n",
    "print(evaluation)\n",
    "\n",
    "print(\"Apply point-to-point ICP\")\n",
    "reg_p2p = registration_icp(source, target, threshold, trans_init,\n",
    "        TransformationEstimationPointToPoint())\n",
    "print(reg_p2p)\n",
    "print(\"Transformation is:\")\n",
    "print(reg_p2p.transformation)\n",
    "print(\"\")\n",
    "draw_registration_result(source, target, reg_p2p.transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial alignment\n",
      "RegistrationResult with fitness = 1.000000, inlier_rmse = 0.267580, and correspondence_set size of 11017\n",
      "Access transformation to get result.\n",
      "Apply point-to-point ICP\n",
      "Apply point-to-point ICP\n",
      "Apply point-to-point ICP\n",
      "Apply point-to-point ICP\n",
      "Apply point-to-point ICP\n",
      "Apply point-to-point ICP\n",
      "Apply point-to-point ICP\n",
      "Apply point-to-point ICP\n",
      "Apply point-to-point ICP\n",
      "Apply point-to-point ICP\n"
     ]
    }
   ],
   "source": [
    "source = read_point_cloud(model_path)\n",
    "source.paint_uniform_color([1, 0.706, 0])\n",
    "target = read_point_cloud(scene_path)\n",
    "threshold = 1.0\n",
    "trans_init = np.asarray(\n",
    "            [[1, 0.011, -0.507,  0],\n",
    "            [-0.139, 1, -0.215,  -1],\n",
    "            [0.487, 0.255,  1, 0.8],\n",
    "            [0.0, 0.0, 0.0, 1.0]])\n",
    "draw_registration_result(source, target, trans_init)\n",
    "print(\"Initial alignment\")\n",
    "evaluation = evaluate_registration(source, target,\n",
    "        threshold, trans_init)\n",
    "print(evaluation)\n",
    "\n",
    "i=0\n",
    "current_pose = trans_init\n",
    "while i<10 :\n",
    "    print(\"Apply point-to-point ICP\")\n",
    "    reg_p2p = registration_icp(source, target, threshold, current_pose,\n",
    "            TransformationEstimationPointToPoint())\n",
    "    #print(reg_p2p.fitness)\n",
    "    #print(\"Transformation is:\")\n",
    "    #print(reg_p2p.transformation)\n",
    "    #print(\"\")\n",
    "    draw_registration_result(source, target, reg_p2p.transformation)\n",
    "    threshold = threshold/2\n",
    "    current_pose = reg_p2p.transformation\n",
    "    i+=1\n",
    "draw_registration_result(source, target, reg_p2p.transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_init_pringles = np.asarray(\n",
    "            [[1, 0.011, -0.507,  0],\n",
    "            [-0.139, 1, -0.215,  -1],\n",
    "            [0.487, 0.255,  1, 0.8],\n",
    "            [0.0, 0.0, 0.0, 1.0]])\n",
    "\n",
    "trans_init_poubelle = np.asarray(\n",
    "            [[1, 0.011, -0.507,  -0.2],\n",
    "            [-0.139, 1, -0.215,  0],\n",
    "            [0.487, 0.255,  1, 0],\n",
    "            [0.0, 0.0, 0.0, 1.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_registration_result(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.transform(transformation)\n",
    "    draw_geometries([source_temp, target_temp])\n",
    "\n",
    "def preprocess_point_cloud(pcd, voxel_size):\n",
    "    print(\":: Downsample with a voxel size %.3f.\" % voxel_size)\n",
    "    pcd_down = voxel_down_sample(pcd, voxel_size)\n",
    "\n",
    "    radius_normal = voxel_size * 2\n",
    "    print(\":: Estimate normal with search radius %.3f.\" % radius_normal)\n",
    "    estimate_normals(pcd_down, KDTreeSearchParamHybrid(\n",
    "            radius = radius_normal, max_nn = 30))\n",
    "\n",
    "    radius_feature = voxel_size * 5\n",
    "    print(\":: Compute FPFH feature with search radius %.3f.\" % radius_feature)\n",
    "    pcd_fpfh = compute_fpfh_feature(pcd_down,\n",
    "            KDTreeSearchParamHybrid(radius = radius_feature, max_nn = 100))\n",
    "    return pcd_down, pcd_fpfh\n",
    "\n",
    "def prepare_dataset(voxel_size):\n",
    "    print(\":: Load two point clouds and disturb initial pose.\")\n",
    "    source = read_point_cloud(model_path)\n",
    "    target = read_point_cloud(scene_path)\n",
    "    trans_init = np.asarray(\n",
    "                [[1, 0, 0,  0],\n",
    "                [0, 1, 0,  -0.5],\n",
    "                [0, 0,  1, 0.8],\n",
    "                [0.0, 0.0, 0.0, 1.0]])\n",
    "    source.transform(trans_init)\n",
    "    draw_registration_result(source, target, trans_init)\n",
    "\n",
    "    source_down, source_fpfh = preprocess_point_cloud(source, voxel_size)\n",
    "    target_down, target_fpfh = preprocess_point_cloud(target, voxel_size)\n",
    "    return source, target, source_down, target_down, source_fpfh, target_fpfh\n",
    "\n",
    "def execute_global_registration(\n",
    "        source_down, target_down, source_fpfh, target_fpfh, voxel_size):\n",
    "    distance_threshold = voxel_size * 1.5\n",
    "    print(\":: RANSAC registration on downsampled point clouds.\")\n",
    "    print(\"   Since the downsampling voxel size is %.3f,\" % voxel_size)\n",
    "    print(\"   we use a liberal distance threshold %.3f.\" % distance_threshold)\n",
    "    result = registration_ransac_based_on_feature_matching(\n",
    "            source_down, target_down, source_fpfh, target_fpfh,\n",
    "            distance_threshold,\n",
    "            TransformationEstimationPointToPoint(False), 4,\n",
    "            [CorrespondenceCheckerBasedOnEdgeLength(0.9),\n",
    "            CorrespondenceCheckerBasedOnDistance(distance_threshold)],\n",
    "            RANSACConvergenceCriteria(4000000, 500))\n",
    "    return result\n",
    "\n",
    "def refine_registration(source, target, source_fpfh, target_fpfh, voxel_size):\n",
    "    distance_threshold = voxel_size * 0.4\n",
    "    print(\":: Point-to-plane ICP registration is applied on original point\")\n",
    "    print(\"   clouds to refine the alignment. This time we use a strict\")\n",
    "    print(\"   distance threshold %.3f.\" % distance_threshold)\n",
    "    result = registration_icp(source, target, distance_threshold,\n",
    "            result_ransac.transformation,\n",
    "            TransformationEstimationPointToPlane())\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Load two point clouds and disturb initial pose.\n",
      ":: Downsample with a voxel size 0.005.\n",
      ":: Estimate normal with search radius 0.010.\n",
      ":: Compute FPFH feature with search radius 0.025.\n",
      ":: Downsample with a voxel size 0.005.\n",
      ":: Estimate normal with search radius 0.010.\n",
      ":: Compute FPFH feature with search radius 0.025.\n",
      ":: RANSAC registration on downsampled point clouds.\n",
      "   Since the downsampling voxel size is 0.005,\n",
      "   we use a liberal distance threshold 0.007.\n",
      "RegistrationResult with fitness = 0.000000, inlier_rmse = 0.000000, and correspondence_set size of 0\n",
      "Access transformation to get result.\n",
      ":: Point-to-plane ICP registration is applied on original point\n",
      "   clouds to refine the alignment. This time we use a strict\n",
      "   distance threshold 0.002.\n",
      "RegistrationResult with fitness = 0.000000, inlier_rmse = 0.000000, and correspondence_set size of 0\n",
      "Access transformation to get result.\n"
     ]
    }
   ],
   "source": [
    "voxel_size = 0.005 # means 5cm for the dataset\n",
    "source, target, source_down, target_down, source_fpfh, target_fpfh = \\\n",
    "        prepare_dataset(voxel_size)\n",
    "\n",
    "result_ransac = execute_global_registration(source_down, target_down,\n",
    "        source_fpfh, target_fpfh, voxel_size)\n",
    "print(result_ransac)\n",
    "draw_registration_result(source_down, target_down,\n",
    "        result_ransac.transformation)\n",
    "\n",
    "result_icp = refine_registration(source, target,\n",
    "        source_fpfh, target_fpfh, voxel_size)\n",
    "print(result_icp)\n",
    "draw_registration_result(source, target, result_icp.transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
